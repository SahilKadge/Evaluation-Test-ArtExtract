# -*- coding: utf-8 -*-
"""artist_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H7KyqKQhCzMmEIPyPFG1P-YDjrPuOCn6
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
csv_path = './content/MyDrive/drive/data/csv'
artist_train = pd.read_csv('/content/drive/MyDrive/data/csv/Artist/artist_train')
# lets visualize one imag
base_url = '/content/drive/MyDrive/data/images'
# lets start creating data
artist = '/content/drive/MyDrive/data/csv/Artist'
genre = '/content/drive/MyDrive/data/csv/Genre'
style = '/content/drive/MyDrive/data/csv/Style'
data_dir = '/content/drive/MyDrive/data/csv'

artist_train_path = data_dir + '/artist_train.csv'
artist_val_path = data_dir + '/artist_val.csv'
artist_class_path = data_dir + '/artist_class.txt'

genre_train_path = data_dir + '/genre_train.csv'
genre_val_path = data_dir + '/genre_val.csv'
genre_class_path = data_dir + '/genre_class.txt'

style_train_path = data_dir + '/style_train.csv'
style_val_path = data_dir + '/style_val.csv'
style_class_path = data_dir + '/style_class.txt'

artist_train = pd.read_csv(data_dir + '/artist_train.csv')
artist_val = pd.read_csv(data_dir + '/artist_val.csv')
artist_class = pd.read_csv(artist_class_path, header=None, names=["artist_name"])

genre_train = pd.read_csv(data_dir + '/genre_train.csv')
genre_val = pd.read_csv(data_dir + '/genre_val.csv')
genre_class = pd.read_csv(genre_class_path, header=None, names=["genre_name"])


style_train = pd.read_csv(data_dir + '/style_train.csv')
style_val = pd.read_csv(data_dir + '/style_val.csv')
style_class = pd.read_csv(style_class_path, header=None, names=["style_name"])

# genre_class['genre_name'][1]
len(style_class)

import os
import pandas as pd
import torch
from torch.utils.data import Dataset
from torchvision import transforms
from PIL import Image
from collections import defaultdict
import random
from tqdm import tqdm
import matplotlib.pyplot as plt

# Define dataset class
class BalancedArtDataset(Dataset):
    def __init__(self, csv_file, img_dir, class_mapping, transform=None, images_per_class=32):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.class_mapping = class_mapping
        self.transform = transform
        self.images_per_class = images_per_class

        # Filter out missing images
        print("Filtering missing images...")
        self.data = self.data[self.data.iloc[:, 0].apply(lambda x: os.path.exists(os.path.join(img_dir, str(x))))]

        # Group images by class
        print("Grouping images by class...")
        self.class_images = defaultdict(list)
        for _, row in tqdm(self.data.iterrows(), total=len(self.data), desc="Processing rows"):
            self.class_images[row.iloc[1]].append(row)

        # Balance dataset with 32 images per class
        print("Balancing dataset...")
        self.final_data = []
        all_images = []
        for cls, images in tqdm(self.class_images.items(), total=len(self.class_images), desc="Processing classes"):
            if len(images) >= images_per_class:
                selected_images = random.sample(images, images_per_class)
            else:
                selected_images = images[:]
                all_images.extend(images)  # Store extra images for filling
            self.final_data.extend(selected_images)

        # Fill missing slots with extra images
        print("Filling missing slots...")
        needed_images = images_per_class * len(self.class_images) - len(self.final_data)
        if needed_images > 0:
            self.final_data.extend(random.sample(all_images, min(needed_images, len(all_images))))

        # Shuffle dataset
        print("Shuffling dataset...")
        random.shuffle(self.final_data)

        # Count images per class
        self.class_counts = defaultdict(int)
        for row in self.final_data:
            self.class_counts[row.iloc[1]] += 1

    def __len__(self):
        return len(self.final_data)

    def __getitem__(self, idx):
        row = self.final_data[idx]
        img_path = os.path.join(self.img_dir, str(row.iloc[0]))
        label = row.iloc[1]
        image = Image.open(img_path).convert("RGB")

        if self.transform:
            image = self.transform(image)

        return image, label


    def visualize_class_distribution(self):
        plt.figure(figsize=(12, 6))
        plt.bar(self.class_counts.keys(), self.class_counts.values(), color='skyblue')
        plt.xlabel("Class")
        plt.ylabel("Number of Images")
        plt.title("Class Distribution in Balanced Dataset")
        plt.xticks(rotation=45)
        plt.show()

    def visualize_samples(self, num_samples=10):
        fig, axes = plt.subplots(1, num_samples, figsize=(40, 20))
        for i in range(num_samples):
            image, label = self.__getitem__(random.randint(0, len(self) - 1))
            image = image.permute(1, 2, 0).numpy()  # Convert to (H, W, C)
            image = (image * 0.5) + 0.5  # Unnormalize
            axes[i].imshow(image)
            axes[i].set_title(f"Class: {label} {artist_class['artist_name'][label]}")
            axes[i].axis("off")
        plt.show()

    # Function to compare artist and genre relationships



# Define transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# Create balanced artist dataset
print("Creating balanced artist dataset...")
artist_balanced_dataset = BalancedArtDataset(artist_train_path, "/content/drive/MyDrive/data/images", artist_class_path, transform=transform, images_per_class=200)
artist_test_balanced_dataset = BalancedArtDataset(artist_val_path, "/content/drive/MyDrive/data/images", artist_class_path, transform=transform, images_per_class=50)

# Check dataset length
print("Artist balanced dataset size:", len(artist_balanced_dataset), len(artist_test_balanced_dataset))

# Visualize class distribution
artist_balanced_dataset.visualize_class_distribution()

# Visualize sample images
artist_balanced_dataset.visualize_samples(num_samples=10)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models
from torch.utils.data import DataLoader
from tqdm import tqdm

# Check for GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Define DataLoaders
batch_size = 32  # Adjust based on GPU memory

train_loader = DataLoader(artist_balanced_dataset, batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True)
val_loader = DataLoader(artist_test_balanced_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)

print("Dataloaders created successfully!")

# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from tqdm import tqdm
import time

# Hyperparameters
num_epochs_fc = 5        # Train FC layer only for 5 epochs
num_epochs_finetune = 6  # Fine-tune entire model for 6 more epochs
initial_lr = 0.001       # Learning rate for training FC layer
finetune_lr = 1e-4       # Lower learning rate for fine-tuning
batch_size = 32
weight_decay = 1e-4      # L2 regularization

# Define the number of output classes
num_classes = len(artist_class)  # Replace with your actual class count

# Load the ResNet-50 model pre-trained on ImageNet
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)  # Replace the FC layer to match your task

model = model.to(device)  # Move model to the appropriate device (CPU/GPU)

# Define loss function and optimizer for training the FC layer
criterion = nn.CrossEntropyLoss()
fc_optimizer = optim.Adam(model.fc.parameters(), lr=initial_lr, weight_decay=weight_decay)

# Function to train the fully connected (FC) layer only
def train_fc_layer():
    print("Starting Step 1: Training FC Layer Only...")

    # Freeze all layers except the FC layer
    for param in model.parameters():
        param.requires_grad = False

    # Ensure the new FC layer is trainable
    for param in model.fc.parameters():
        param.requires_grad = True

    model.train()  # Set the model to training mode

    for epoch in range(num_epochs_fc):
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_fc}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            # Zero the gradients
            fc_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()  # Backpropagation
            fc_optimizer.step()  # Update FC layer weights

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        print(f"Epoch [{epoch+1}/{num_epochs_fc}], Loss: {running_loss / len(train_loader):.4f}, "
              f"Accuracy: {100 * correct / total:.2f}%")

    print("ðŸŽ¯ Step 1 Complete: FC Layer Training Finished!")


# Function to fine-tune the entire ResNet-50 network
def fine_tune():
    print("Starting Step 2: Fine-Tuning the Entire Network...")

    # Unfreeze all layers
    for param in model.parameters():
        param.requires_grad = True

    # Define optimizer and learning rate scheduler for fine-tuning
    finetune_optimizer = optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(finetune_optimizer, mode='min', factor=0.1, patience=3, verbose=True)

    best_val_loss = float('inf')

    for epoch in range(num_epochs_finetune):
        model.train()
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_finetune}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            finetune_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()
            finetune_optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        # Validation phase
        val_loss, val_acc = evaluate(val_loader)
        scheduler.step(val_loss)

        print(f"Epoch [{epoch+1}/{num_epochs_finetune}], "
              f"Train Loss: {running_loss / len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%, "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        # Save the best model based on validation loss
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "/content/drive/MyDrive/art_model/best_resnet50_model.pth")
            print("âœ… Best model saved!")

    print("ðŸŽ¯ Step 2 Complete: Fine-Tuning Finished!")


# Function to evaluate the model on validation data
def evaluate(loader):
    model.eval()
    val_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    avg_loss = val_loss / len(loader)
    accuracy = 100 * correct / total
    return avg_loss, accuracy


# Start training
train_fc_layer()  # Step 1: Train FC Layer only
fine_tune()       # Step 2: Fine-tune the entire ResNet-50 model

print("ðŸŽ‰ Training complete! The best model is saved as 'best_resnet50_model.pth'.")

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from tqdm import tqdm
import time

# Hyperparameters
num_epochs_fc = 5        # Train FC layer only for 5 epochs
num_epochs_finetune = 6  # Fine-tune entire model for 6 more epochs
initial_lr = 0.001       # Learning rate for training FC layer
finetune_lr = 1e-4       # Lower learning rate for fine-tuning
batch_size = 32
weight_decay = 1e-4      # L2 regularization
hidden_size = 256        # Hidden size for LSTM
num_layers = 2           # Number of LSTM layers

# Define the number of output classes
num_classes = len(artist_class)  # Replace with your actual class count

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define a hybrid model combining ResNet-50 and an LSTM
class ResNetRNN(nn.Module):
    def __init__(self, num_classes, hidden_size=256, num_layers=2):
        super(ResNetRNN, self).__init__()
        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        self.resnet.fc = nn.Identity()  # Remove FC layer to get feature maps

        # LSTM layer to process sequential features from ResNet's output
        self.lstm = nn.LSTM(input_size=2048, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)

        # Fully connected layer after LSTM
        self.fc = nn.Linear(hidden_size * 2, num_classes)  # Bidirectional doubles the hidden size

    def forward(self, x):
        batch_size, _, _, _ = x.size()

        # Extract features using ResNet
        features = self.resnet(x)  # Shape: (batch_size, 2048)
        features = features.unsqueeze(1)  # Add time dimension: (batch_size, 1, 2048)

        # Pass features through LSTM
        lstm_out, _ = self.lstm(features)  # Shape: (batch_size, 1, hidden_size * 2)
        lstm_out = lstm_out[:, -1, :]  # Get the output of the last time step

        # Final classification
        output = self.fc(lstm_out)
        return output

model = ResNetRNN(num_classes=num_classes, hidden_size=hidden_size, num_layers=num_layers).to(device)

# Define loss function and optimizer for training the FC layer
criterion = nn.CrossEntropyLoss()
fc_optimizer = optim.Adam(model.fc.parameters(), lr=initial_lr, weight_decay=weight_decay)

# Function to train the fully connected (FC) layer only
def train_fc_layer():
    print("Starting Step 1: Training FC Layer Only...")

    # Freeze all layers except the FC layer
    for param in model.parameters():
        param.requires_grad = False

    # Ensure the new FC layer and LSTM are trainable
    for param in model.fc.parameters():
        param.requires_grad = True
    for param in model.lstm.parameters():
        param.requires_grad = True

    model.train()  # Set the model to training mode

    for epoch in range(num_epochs_fc):
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_fc}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            # Zero the gradients
            fc_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()  # Backpropagation
            fc_optimizer.step()  # Update FC layer weights

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        print(f"Epoch [{epoch+1}/{num_epochs_fc}], Loss: {running_loss / len(train_loader):.4f}, "
              f"Accuracy: {100 * correct / total:.2f}%")

    print("\ud83c\udfaf Step 1 Complete: FC Layer Training Finished!")


# Function to fine-tune the entire ResNet-LSTM network
def fine_tune():
    print("Starting Step 2: Fine-Tuning the Entire Network...")

    # Unfreeze all layers
    for param in model.parameters():
        param.requires_grad = True

    # Define optimizer and learning rate scheduler for fine-tuning
    finetune_optimizer = optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(finetune_optimizer, mode='min', factor=0.1, patience=3, verbose=True)

    best_val_loss = float('inf')

    for epoch in range(num_epochs_finetune):
        model.train()
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_finetune}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            finetune_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()
            finetune_optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        # Validation phase
        val_loss, val_acc = evaluate(val_loader)
        scheduler.step(val_loss)

        print(f"Epoch [{epoch+1}/{num_epochs_finetune}], "
              f"Train Loss: {running_loss / len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%, "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        # Save the best model based on validation loss
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "/content/drive/MyDrive/art_model/best_resnet_lstm_model.pth")
            print("\u2705 Best model saved!")

    print("\ud83c\udfaf Step 2 Complete: Fine-Tuning Finished!")


# Function to evaluate the model on validation data
def evaluate(loader):
    model.eval()
    val_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    avg_loss = val_loss / len(loader)
    accuracy = 100 * correct / total
    return avg_loss, accuracy


# Start training
train_fc_layer()  # Step 1: Train FC Layer only
fine_tune()       # Step 2: Fine-tune the entire ResNet-LSTM model

print("\ud83c\udf89 Training complete! The best model is saved as 'best_resnet_lstm_model.pth'.")

# Initialize ResNet-50 model (because the saved checkpoint is from ResNet-50)
model1 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
model1.fc = nn.Linear(model1.fc.in_features, num_classes).to(device)  # Replace the FC layer
model1 = model1.to(device)

# Load the correct saved state dictionary (ResNet-50 checkpoint)
model1.load_state_dict(torch.load("/content/drive/MyDrive/art_model/best_resnet50_model.pth"))

# Print model

import torch
import matplotlib.pyplot as plt
import random


# Function to visualize random predictions from test dataset
def visualize_random_predictions(model, dataset, class_mapping, num_samples=8):
    model.eval()  # Set model to evaluation mode
    fig, axes = plt.subplots(1, num_samples, figsize=(20, 8))

    with torch.no_grad():  # Disable gradient calculation for inference
        for i in range(num_samples):
            # Pick a random index from the dataset
            idx = random.randint(0, len(dataset) - 1)
            image, true_label = dataset[idx]

            # Add batch dimension and move image to the appropriate device
            image_batch = image.unsqueeze(0).to(device)

            # Make a prediction
            output = model(image_batch)
            _, predicted_label = torch.max(output, 1)

            # Convert image tensor to numpy and unnormalize
            image = image.permute(1, 2, 0).cpu().numpy()  # Convert (C, H, W) -> (H, W, C)
            image = (image * 0.5) + 0.5  # Unnormalize image

            # Display the image and predictions
            axes[i].imshow(image)
            axes[i].set_title(
                f"True: {class_mapping['artist_name'][true_label]} \nPredicted: {class_mapping['artist_name'][predicted_label.item()]}",
                color=("green" if true_label == predicted_label.item() else "red"),
                fontsize=12,
            )
            axes[i].axis("off")

    plt.show()



# Visualize random predictions on test dataset (Adjust `num_samples` as needed)
visualize_random_predictions(model1, artist_test_balanced_dataset, artist_class, num_samples=8)

num_classes = len(artist_class)  # Number of output classes
model2 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
model2.fc = nn.Linear(model2.fc.in_features, num_classes).to(device)  # Replace final FC layer
model2 = model2.to(device)
# Load the correct saved state dictionary (ResNet-50 checkpoint)
model2.load_state_dict(torch.load("/content/drive/MyDrive/art_model/best_resnet18_model_200.pth"))

import torch
import matplotlib.pyplot as plt
import random


# Function to visualize random predictions from test dataset on the same images for both models
def visualize_same_random_predictions(model1, model2, dataset, class_mapping, num_samples=8):
    model1.eval()  # Set models to evaluation mode
    model2.eval()

    fig, axes = plt.subplots(2, num_samples, figsize=(20, 12))  # Two rows: one for each model

    # Generate fixed random indices to ensure both models predict on the same images
    fixed_indices = [random.randint(0, len(dataset) - 1) for _ in range(num_samples)]

    with torch.no_grad():  # Disable gradient calculation for inference
        for i, idx in enumerate(fixed_indices):
            image, true_label = dataset[idx]

            # Add batch dimension and move image to the appropriate device
            image_batch = image.unsqueeze(0).to(device)

            # Make predictions with both models
            output1 = model1(image_batch)
            output2 = model2(image_batch)
            _, predicted_label1 = torch.max(output1, 1)
            _, predicted_label2 = torch.max(output2, 1)

            # Convert image tensor to numpy and unnormalize
            image = image.permute(1, 2, 0).cpu().numpy()  # Convert (C, H, W) -> (H, W, C)
            image = (image * 0.5) + 0.5  # Unnormalize image

            # Display the image and predictions for model1 (top row)
            axes[0, i].imshow(image)
            axes[0, i].set_title(
                f"Model 1 - True: {class_mapping['artist_name'][true_label]} \nPredicted: {class_mapping['artist_name'][predicted_label1.item()]}",
                color=("green" if true_label == predicted_label1.item() else "red"),
                fontsize=12,
            )
            axes[0, i].axis("off")

            # Display the image and predictions for model2 (bottom row)
            axes[1, i].imshow(image)
            axes[1, i].set_title(
                f"Model 2 - True: {class_mapping['artist_name'][true_label]} \nPredicted: {class_mapping['artist_name'][predicted_label2.item()]}",
                color=("green" if true_label == predicted_label2.item() else "red"),
                fontsize=12,
            )
            axes[1, i].axis("off")

    plt.show()


# Visualize random predictions on test dataset for both models on the same set of images
visualize_same_random_predictions(model1, model2, artist_test_balanced_dataset, artist_class, num_samples=8)

# Import necessary libraries
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from tqdm import tqdm
import time

# Hyperparameters
num_epochs_fc = 5        # Train FC layer only for 5 epochs
num_epochs_finetune = 6  # Fine-tune entire model for 6 more epochs
initial_lr = 0.001       # Learning rate for training FC layer
finetune_lr = 1e-4       # Lower learning rate for fine-tuning
batch_size = 32
weight_decay = 1e-4      # L2 regularization

# Define the number of output classes
num_classes = len(artist_class)  # Replace with your actual class count

# Load the ResNet-50 model pre-trained on ImageNet
model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
model.fc = nn.Linear(model.fc.in_features, num_classes).to(device)  # Replace the FC layer to match your task

model = model.to(device)  # Move model to the appropriate device (CPU/GPU)

# Define loss function and optimizer for training the FC layer
criterion = nn.CrossEntropyLoss()
fc_optimizer = optim.Adam(model.fc.parameters(), lr=initial_lr, weight_decay=weight_decay)
fc_scheduler = ReduceLROnPlateau(fc_optimizer, mode='min', factor=0.1, patience=2, verbose=True)  # FC stage LR scheduler

# Function to train the fully connected (FC) layer only
def train_fc_layer():
    print("Starting Step 1: Training FC Layer Only...")

    # Freeze all layers except the FC layer
    for param in model.parameters():
        param.requires_grad = False

    # Ensure the new FC layer is trainable
    for param in model.fc.parameters():
        param.requires_grad = True

    model.train()  # Set the model to training mode

    for epoch in range(num_epochs_fc):
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_fc}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            # Zero the gradients
            fc_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()  # Backpropagation
            fc_optimizer.step()  # Update FC layer weights

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        # Evaluate on validation set and update the scheduler
        val_loss, val_acc = evaluate(val_loader)
        fc_scheduler.step(val_loss)

        print(f"Epoch [{epoch+1}/{num_epochs_fc}], Loss: {running_loss / len(train_loader):.4f}, "
              f"Accuracy: {100 * correct / total:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

    print("ðŸŽ¯ Step 1 Complete: FC Layer Training Finished!")


# Function to fine-tune the entire ResNet-50 network
def fine_tune():
    print("Starting Step 2: Fine-Tuning the Entire Network...")

    # Unfreeze all layers
    for param in model.parameters():
        param.requires_grad = True

    # Define optimizer and learning rate scheduler for fine-tuning
    finetune_optimizer = optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=weight_decay)
    finetune_scheduler = ReduceLROnPlateau(finetune_optimizer, mode='min', factor=0.1, patience=3, verbose=True)

    best_val_loss = float('inf')

    for epoch in range(num_epochs_finetune):
        model.train()
        running_loss, correct, total = 0.0, 0, 0
        loop = tqdm(train_loader, leave=True, desc=f"Epoch [{epoch+1}/{num_epochs_finetune}]")

        for images, labels in loop:
            images, labels = images.to(device), labels.to(device)

            finetune_optimizer.zero_grad()

            # Forward pass
            outputs = model(images)

            # Compute loss
            loss = criterion(outputs, labels)
            loss.backward()
            finetune_optimizer.step()

            running_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            # Update the progress bar
            loop.set_postfix(loss=running_loss / len(train_loader), acc=100 * correct / total)

        # Validation phase and scheduler step
        val_loss, val_acc = evaluate(val_loader)
        finetune_scheduler.step(val_loss)

        print(f"Epoch [{epoch+1}/{num_epochs_finetune}], "
              f"Train Loss: {running_loss / len(train_loader):.4f}, Train Acc: {100 * correct / total:.2f}%, "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")

        # Save the best model based on validation loss
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), "/content/drive/MyDrive/art_model/best_resnet50_model_ReduceLROnPlateau.pth")
            print("âœ… Best model saved!")

    print("ðŸŽ¯ Step 2 Complete: Fine-Tuning Finished!")


# Function to evaluate the model on validation data
def evaluate(loader):
    model.eval()
    val_loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    avg_loss = val_loss / len(loader)
    accuracy = 100 * correct / total
    return avg_loss, accuracy


# Start training
train_fc_layer()  # Step 1: Train FC Layer only
fine_tune()       # Step 2: Fine-tune the entire ResNet-50 model

print("ðŸŽ‰ Training complete! The best model is saved as 'best_resnet50_model.pth'.")
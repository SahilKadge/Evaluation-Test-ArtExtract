# -*- coding: utf-8 -*-
"""task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16q7ZA-ec6eapzNp6omrLOzgGP8H7a7Ci
"""



from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

data_path = "/content/drive/MyDrive/artExtract.csv"
dataset = pd.read_csv(data_path)
dataset.head()

import pandas as pd
import requests
from io import BytesIO
from PIL import Image
import torch
import torchvision.models as models
import torchvision.transforms as transforms
import numpy as np
import os
from tqdm import tqdm  # Import tqdm for the progress bar

# Load the dataset (replace 'your_dataset.csv' with your actual dataset path)

df = pd.read_csv(data_path)

# Take a random 10% sample of the dataset
df = df.sample(frac=0.05, random_state=42).reset_index(drop=True)

# Load pre-trained ResNet model for feature extraction
model = models.resnet50(pretrained=True)
model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the final classification layer
model.eval()  # Set model to evaluation mode

# Define image transformations (resize, normalize, etc.)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create a directory to store downloaded images if it doesn't exist
if not os.path.exists("images"):
    os.makedirs("images")

# Function to download and preprocess images from URLs
def download_and_preprocess_image(url, image_id):
    try:
        response = requests.get(url)
        image = Image.open(BytesIO(response.content)).convert('RGB')
        image_path = f"images/{image_id}.jpg"
        image.save(image_path)
        return image_path
    except Exception as e:
        print(f"Error downloading or processing image {image_id}: {e}")
        return None

# Function to extract features from an image
def extract_features(image_path):
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0)  # Add batch dimension
    with torch.no_grad():
        features = model(image).squeeze().numpy()
    return features

# Iterate through the 10% sample, download images, extract features, and save them
image_features = {}
for idx, row in tqdm(df.iterrows(), total=len(df), desc="Processing images", ncols=100):
    image_id = row['uuid']
    image_url = row['iiifthumburl']  # URL of the thumbnail image

    # Download and preprocess the image
    image_path = download_and_preprocess_image(image_url, image_id)
    if image_path:
        # Extract and store features
        features = extract_features(image_path)
        image_features[image_id] = features

# Save features to a file for future use (e.g., as a NumPy file)
np.save("image_features.npy", image_features)

print("Image processing and feature extraction completed!")

import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()  # Load as dictionary

# Convert image feature dictionary to an array
X = np.array(list(image_features.values()))

# Perform KMeans clustering (let's try 5 clusters)
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(X)

# Display clustering results
for idx, cluster in enumerate(clusters):
    print(f"Image ID: {list(image_features.keys())[idx]}, Cluster: {cluster}")

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Perform PCA for 2D visualization
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Plot clusters in 2D (if you have unsupervised clusters)
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', s=10)
plt.title("2D PCA Visualization of Image Clusters")
plt.show()

import numpy as np
import pandas as pd
import random
import requests
from io import BytesIO
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()

# Load dataset (replace 'your_dataset.csv' with actual path)
df = pd.read_csv(data_path)  # Replace with actual path

# Take a random 5% sample (to match feature extraction process)
df = df.sample(frac=0.05).reset_index(drop=True)

# Get all available image IDs that have extracted features
available_images = df[df['uuid'].isin(image_features.keys())]

# Ensure there are at least two images
if len(available_images) < 2:
    print("Not enough images with extracted features to compare.")
else:
    # Randomly select two image IDs
    selected_images = available_images.sample(2, random_state=42)  # Select 2 random images
    # image_id_1, image_id_2 = selected_images['uuid'].values
    # image_url_1, image_url_2 = selected_images['iiifthumburl'].values  # Get image URLs
    image_id_1 = 'd57307be-f4a4-4ee4-a7c7-8d2fa6a91010'
    image_id_2 = 'b0e9ed54-0d96-45ab-985d-4887d8920291'
    image_url_1 = 'https://api.nga.gov/iiif/d57307be-f4a4-4ee4-a7c7-8d2fa6a91010/full/!200,200/0/default.jpg'
    image_url_2 = 'https://api.nga.gov/iiif/b0e9ed54-0d96-45ab-985d-4887d8920291/full/!200,200/0/default.jpg'
    # Retrieve their features
    features_1 = image_features[image_id_1].reshape(1, -1)
    features_2 = image_features[image_id_2].reshape(1, -1)

    # Compute Cosine Similarity (higher means more similar)
    similarity = cosine_similarity(features_1, features_2)[0][0]

    # Compute Euclidean Distance (lower means more similar)
    euclidean_distance = np.linalg.norm(features_1 - features_2)

    # Download and open the images
    response_1 = requests.get(image_url_1)
    response_2 = requests.get(image_url_2)
    image_1 = Image.open(BytesIO(response_1.content))
    image_2 = Image.open(BytesIO(response_2.content))

    # Plot images side-by-side with similarity scores
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    axes[0].imshow(image_1)
    axes[0].axis('off')
    axes[0].set_title(f"Image 1: {image_id_1}")

    axes[1].imshow(image_2)
    axes[1].axis('off')
    axes[1].set_title(f"Image 2: {image_id_2}")

    # Add similarity metrics as a title
    plt.suptitle(f"Cosine Similarity: {similarity:.4f} | Euclidean Distance: {euclidean_distance:.4f}", fontsize=12, fontweight='bold')
    print(f"image id 1: {image_id_1} image_id_2 : {image_id_2}")
    print(f"image id 1: {image_url_1} image_id_2 : {image_url_2}")

    plt.show()

import numpy as np
import pandas as pd
import random
import requests
from io import BytesIO
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import cosine_similarity

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()

# Load dataset (replace 'your_dataset.csv' with actual path)
df = pd.read_csv(data_path)  # Replace with actual path

# Take a random 5% sample (to match feature extraction process)
df = df.sample(frac=0.05).reset_index(drop=True)

# Get all available image IDs that have extracted features
available_images = df[df['uuid'].isin(image_features.keys())]

# Ensure there are at least two images
if len(available_images) < 2:
    print("Not enough images with extracted features to compare.")
else:
    # Randomly select two image IDs
    selected_images = available_images.sample(2, random_state=42)  # Select 2 random images
    # image_id_1, image_id_2 = selected_images['uuid'].values
    # image_url_1, image_url_2 = selected_images['iiifthumburl'].values  # Get image URLs
    # image_id_1 = '5a0d5e53-5230-4159-bda4-e85a04d168df'
    # image_url_1 = 'https://api.nga.gov/iiif/5a0d5e53-5230-4159-bda4-e85a04d168df/full/!200,200/0/default.jpg'
    image_id_1 = 'b0e9ed54-0d96-45ab-985d-4887d8920291'
    image_url_1 = 'https://api.nga.gov/iiif/b0e9ed54-0d96-45ab-985d-4887d8920291/full/!200,200/0/default.jpg'
    image_id_2 = 'b0e9ed54-0d96-45ab-985d-4887d8920291'
    image_url_2 = 'https://api.nga.gov/iiif/b0e9ed54-0d96-45ab-985d-4887d8920291/full/!200,200/0/default.jpg'
    # Retrieve their features
    features_1 = image_features[image_id_1].reshape(1, -1)
    features_2 = image_features[image_id_2].reshape(1, -1)

    # Compute Cosine Similarity (higher means more similar)
    similarity = cosine_similarity(features_1, features_2)[0][0]

    # Compute Euclidean Distance (lower means more similar)
    euclidean_distance = np.linalg.norm(features_1 - features_2)

    # Download and open the images
    response_1 = requests.get(image_url_1)
    response_2 = requests.get(image_url_2)
    image_1 = Image.open(BytesIO(response_1.content))
    image_2 = Image.open(BytesIO(response_2.content))

    # Plot images side-by-side with similarity scores
    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    axes[0].imshow(image_1)
    axes[0].axis('off')
    axes[0].set_title(f"Image 1: {image_id_1}")

    axes[1].imshow(image_2)
    axes[1].axis('off')
    axes[1].set_title(f"Image 2: {image_id_2}")

    # Add similarity metrics as a title
    plt.suptitle(f"Cosine Similarity: {similarity:.4f} | Euclidean Distance: {euclidean_distance:.4f}", fontsize=12, fontweight='bold')
    print(f"image id 1: {image_id_1} image_id_2 : {image_id_2}")
    print(f"image id 1: {image_url_1} image_id_2 : {image_url_2}")

    plt.show()

68ea9c63-6b30-41d0-bbac-ec6db21bc9fb
https://api.nga.gov/iiif/68ea9c63-6b30-41d0-bbac-ec6db21bc9fb/full/!200,200/0/default.jpg

5a0d5e53-5230-4159-bda4-e85a04d168df
 https://api.nga.gov/iiif/5a0d5e53-5230-4159-bda4-e85a04d168df/full/!200,200/0/default.jpg

image_id_1 = 'd41e6b2a-980d-450b-bc65-404941bf53e1'
image_url_1 = 'https://api.nga.gov/iiif/d41e6b2a-980d-450b-bc65-404941bf53e1/full/!200,200/0/default.jpg'

b0e9ed54-0d96-45ab-985d-4887d8920291
https://api.nga.gov/iiif/b0e9ed54-0d96-45ab-985d-4887d8920291/full/!200,200/0/default.jpg

d57307be-f4a4-4ee4-a7c7-8d2fa6a91010
https://api.nga.gov/iiif/d57307be-f4a4-4ee4-a7c7-8d2fa6a91010/full/!200,200/0/default.jpg

image_id_2 = 'b0e9ed54-0d96-45ab-985d-4887d8920291'

image_url_2 = 'https://api.nga.gov/iiif/b0e9ed54-0d96-45ab-985d-4887d8920291/full/!200,200/0/default.jpg'

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()
X = np.array(list(image_features.values()))  # Convert to array

# Try different k values
inertia_values = []
k_values = range(1, 100)  # Try k from 1 to 10

for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertia_values.append(kmeans.inertia_)  # Store inertia (sum of squared distances)

# Plot the Elbow Curve
plt.figure(figsize=(8, 5))
plt.plot(k_values, inertia_values, marker="o", linestyle="-")
plt.xlabel("Number of Clusters (k)")
plt.ylabel("Inertia (Sum of Squared Distances)")
plt.title("Elbow Method for Optimal k")
plt.xticks(k_values)
plt.grid()
plt.show()

from sklearn.metrics import silhouette_score

best_k = 2  # Start from 2 (since k=1 has no separation)
best_score = -1

for k in range(2, 100):  # Try different k values
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)  # Compute silhouette score

    print(f"k={k}, Silhouette Score={score:.4f}")

    if score > best_score:
        best_k = k
        best_score = score

print(f"\nOptimal Number of Clusters: {best_k}")

"""## Agglomerative Hierarchical Clustering (Recommended)"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()
X = np.array(list(image_features.values()))  # Convert dictionary values to array
image_ids = list(image_features.keys())  # Get image IDs

# Perform Hierarchical Clustering
Z = linkage(X, method="ward")  # 'ward' minimizes variance within clusters

# Plot Dendrogram
plt.figure(figsize=(10, 5))
dendrogram(Z, labels=image_ids, leaf_rotation=90, leaf_font_size=8)
plt.title("Hierarchical Clustering Dendrogram")
plt.xlabel("Image ID")
plt.ylabel("Distance")
plt.show()

# Decide number of clusters (e.g., cut at 2 clusters)
num_clusters = 2
clusters = fcluster(Z, num_clusters, criterion="maxclust")

# Print Clustering Results
for img_id, cluster in zip(image_ids, clusters):
    print(f"Image ID: {img_id}, Cluster: {cluster}")

import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()
X = np.array(list(image_features.values()))  # Convert dictionary values to array
image_ids = list(image_features.keys())  # Get image IDs

# Perform Hierarchical Clustering
Z = linkage(X, method="ward")  # 'ward' minimizes variance within clusters

# Plot Dendrogram with threshold line
plt.figure(figsize=(12, 6))
dendrogram(Z, labels=image_ids, leaf_rotation=90, leaf_font_size=8)
plt.axhline(y=150, color='r', linestyle='--')  # Adjust threshold line manually
plt.title("Hierarchical Clustering Dendrogram")
plt.xlabel("Image ID")
plt.ylabel("Distance")
plt.show()

# Choose clusters based on the dendrogram gap
optimal_clusters = 3  # Set based on the largest vertical gap in the dendrogram
clusters = fcluster(Z, optimal_clusters, criterion="maxclust")

# Print Clustering Results
for img_id, cluster in zip(image_ids, clusters):
    print(f"Image ID: {img_id}, Cluster: {cluster}")

import numpy as np
import matplotlib.pyplot as plt
from scipy.cluster.hierarchy import linkage, fcluster
from PIL import Image
import pandas as pd
import requests
from io import BytesIO
import random

# Load saved image features
image_features = np.load("image_features.npy", allow_pickle=True).item()
X = np.array(list(image_features.values()))  # Convert dictionary values to array
image_ids = list(image_features.keys())  # Get image IDs

# Load dataset (assuming it contains 'uuid' and 'iiifurl' columns)
# Replace with actual dataset path
df = pd.read_csv(data_path)
image_path_mapping = dict(zip(df["uuid"], df["iiifurl"]))  # Map UUID to image URLs

# Perform Hierarchical Clustering
Z = linkage(X, method="ward")  # 'ward' minimizes variance within clusters

# Determine optimal cluster count using the largest gap
distances = Z[:, 2]  # Extract merge distances
jumps = np.diff(distances)
optimal_threshold = distances[np.argmax(jumps)]  # Cut at the largest jump

# Assign clusters
clusters = fcluster(Z, optimal_threshold, criterion="distance")

# Create a mapping of image IDs to clusters
cluster_mapping = {img_id: cluster for img_id, cluster in zip(image_ids, clusters)}

# Convert clusters to cluster centroids (average of points in each cluster)
unique_clusters = np.unique(clusters)
cluster_centroids = {
    cluster: np.mean(X[np.array(clusters) == cluster], axis=0)
    for cluster in unique_clusters
}

# 🔹 Function to Predict the Cluster for a New Image
def predict_cluster(new_image_feature):
    new_image_feature = np.array(new_image_feature).reshape(1, -1)
    cluster_distances = {cluster: np.linalg.norm(new_image_feature - centroid) for cluster, centroid in cluster_centroids.items()}
    predicted_cluster = min(cluster_distances, key=cluster_distances.get)  # Closest cluster
    return predicted_cluster

# 🔹 Function to Display an Image from IIIF URL
def display_image(image_id, predicted_cluster):
    base_url = image_path_mapping.get(image_id, None)
    if base_url:
        # Append IIIF parameters for a valid image request
        image_url = f"{base_url}/full/full/0/default.jpg"
        try:
            response = requests.get(image_url)
            response.raise_for_status()  # Ensure we got a valid response
            img = Image.open(BytesIO(response.content))  # Load image from URL
            plt.imshow(img)
            plt.axis("off")
            plt.title(f"Image ID: {image_id}\nPredicted Cluster: {predicted_cluster}")
            plt.show()
        except requests.exceptions.RequestException as e:
            print(f"Error loading image from URL: {e}")
        except Image.UnidentifiedImageError:
            print(f"Could not identify image for {image_id}. Check the IIIF URL format.")
    else:
        print(f"Image URL for {image_id} not found!")

# 🔹 Select 10 Random Images from Dataset
random_image_ids = random.sample(image_ids, 10)  # Pick 10 random images

# 🔹 Loop through the images, predict clusters, and display them
for idx, image_id in enumerate(random_image_ids, start=1):
    image_feature = image_features[image_id]  # Get its feature vector
    predicted_cluster = predict_cluster(image_feature)  # Predict cluster

    print(f"🔹 Image {idx}: {image_id}")
    print(f"   Predicted Cluster: {predicted_cluster}")

    # Display the image
    display_image(image_id, predicted_cluster)

"""cluster 1 line painting
cluster 2 smooth painting
cluster 3 object painting
"""

